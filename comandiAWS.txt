METTERE FILE:

scp -i ~/.ssh/pem/elisa_catena_big_data_2024.pem -r ~/git/Big-Data-Profiling/Airline.csv ec2-18-204-10-39.compute-1.amazonaws.com:~

scp -i ~/.ssh/pem/elisa_catena_big_data_2024.pem -r ~/git/Big-Data-Profiling/song_lyrics.csv.zip ec2-18-204-10-39.compute-1.amazonaws.com:~

scp -i ~/.ssh/pem/elisa_catena_big_data_2024.pem -r ~/git/Big-Data-Profiling/YdataZIP.py ec2-18-204-10-39.compute-1.amazonaws.com:~


ACCEDERE AL MASTER NODE:

ssh -i ~/.ssh/pem/elisa_catena_big_data_2024.pem ec2-18-204-10-39.compute-1.amazonaws.com

hdfs dfs -mkdir /input


SPOSTARE I FILE NEL MASTER NODE:

hdfs dfs -put song_lyrics.csv.zip /input/song_lyrics.csv.zip 


LIBRERIE:
pip install matplotlib
pip install pyspark
pip install ydata_profiling
pip uninstall urllib3
pip install urllib3==1.26.14


LANCIARE IL JOB:

$SPARK_HOME/bin/spark-submit --master yarn YdataZIP.py --input_path hdfs:///input/song_lyrics.csv.zip


SPOSTARE L'OUTPUT SUL DESKTOP:
scp -i /Users/elisacatena/.ssh/pem/elisa_catena_big_data_2024.pem ec2-18-204-10-39.compute-1.amazonaws.com:airline_report.html ~/Desktop/


VEDERE IL RISULTATO:

hdfs dfs -ls /input
hdfs dfs -ls /output


ELIMINARE FILE O CARTELLE:
hdfs dfs -rm -r /output
hdfs dfs -rm -r /input

rm airline_report.html
rm song_lyrics_report.html
rm YdataGZ.py 


