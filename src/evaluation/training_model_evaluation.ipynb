{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/29/hp9758mj5zj7dcbpxts76vt00000gn/T/ipykernel_79532/3781380141.py:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dirty_data = pd.read_csv('../../datasets/initial_datasets/dirty_titles.csv')\n"
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "dirty_data = pd.read_csv('../../datasets/initial_datasets/dirty_titles.csv')\n",
    "clean_data = pd.read_csv('../../datasets/cleaned_datasets/cleaned_titles.csv', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.read_csv('../../datasets/cleaned_datasets/cleaned_titles.csv', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per generare una stringa casuale di 6 caratteri\n",
    "def random_string(length=6):\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for i in range(length))\n",
    "\n",
    "def replace_null_or_n(value, column):\n",
    "    if pd.isnull(value) or value == r\"\\N\":\n",
    "        if column == 'genres':\n",
    "            return random_string()\n",
    "        elif column in ['titleType', 'primaryTitle', 'originalTitle']:\n",
    "            return 'null_value'\n",
    "        elif column == 'isAdult':\n",
    "            return 1\n",
    "        elif column in ['startYear', 'endYear']:\n",
    "            return 1900\n",
    "        elif column == 'runtimeMinutes':\n",
    "            return 1\n",
    "        elif column == 'tconst': \n",
    "            return 'tttttttttt00'\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                tconst   titleType primaryTitle originalTitle isAdult  \\\n",
      "64027483  tttttttttt00  null_value   null_value    null_value       1   \n",
      "64027484  tttttttttt00  null_value   null_value    null_value       1   \n",
      "64027485  tttttttttt00  null_value   null_value    null_value       1   \n",
      "64027486  tttttttttt00  null_value   null_value    null_value       1   \n",
      "64027487  tttttttttt00  null_value   null_value    null_value       1   \n",
      "\n",
      "         startYear endYear runtimeMinutes  genres  \n",
      "64027483      1900    1900              1  bfpcnt  \n",
      "64027484      1900    1900              1  pjabqx  \n",
      "64027485      1900    1900              1  qozrll  \n",
      "64027486      1900    1900              1  qjpslu  \n",
      "64027487      1900    1900              1  vqjfbd  \n"
     ]
    }
   ],
   "source": [
    "# Applica la funzione a tutte le colonne del DataFrame\n",
    "for column in dirty_data.columns:\n",
    "    dirty_data[column] = dirty_data[column].apply(lambda x: replace_null_or_n(x, column))\n",
    "\n",
    "# Mostra le ultime 5 righe del DataFrame\n",
    "print(dirty_data.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# fields: tconst,titleType,primaryTitle,originalTitle,isAdult,startYear,endYear,runtimeMinutes,genres\n",
    "\n",
    "# Selection of features variables (columns) and target variable (column)\n",
    "features = ['titleType', 'primaryTitle', 'isAdult', 'runtimeMinutes'] \n",
    "target = 'genres'\n",
    "\n",
    "# Creation of dataframes with features and target\n",
    "X_dirty = dirty_data[features]\n",
    "y_dirty = dirty_data[target]\n",
    "\n",
    "X_clean = clean_data[features]\n",
    "y_clean = clean_data[target]\n",
    "\n",
    "# Split data for training and testing\n",
    "X_dirty_train, X_dirty_test, y_dirty_train, y_dirty_test = train_test_split(X_dirty, y_dirty, test_size=0.2, random_state=42)\n",
    "X_clean_train, X_clean_test, y_clean_train, y_clean_test = train_test_split(X_clean, y_clean, test_size=0.2, random_state=42)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 18.5 PiB for an array with shape (64027488, 40693691) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m dirty_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dirty_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      8\u001b[0m mlb \u001b[38;5;241m=\u001b[39m MultiLabelBinarizer()\n\u001b[0;32m----> 9\u001b[0m genres_binarized \u001b[38;5;241m=\u001b[39m mlb\u001b[38;5;241m.\u001b[39mfit_transform(dirty_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Utilizzare TF-IDF per la colonna 'primaryTitle'\u001b[39;00m\n\u001b[1;32m     12\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:833\u001b[0m, in \u001b[0;36mMultiLabelBinarizer.fit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    830\u001b[0m yt\u001b[38;5;241m.\u001b[39mindices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(inverse[yt\u001b[38;5;241m.\u001b[39mindices], dtype\u001b[38;5;241m=\u001b[39myt\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_output:\n\u001b[0;32m--> 833\u001b[0m     yt \u001b[38;5;241m=\u001b[39m yt\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m yt\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/sparse/_compressed.py:1050\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1049\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1050\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_toarray_args(order, out)\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/sparse/_base.py:1267\u001b[0m, in \u001b[0;36m_spbase._process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 18.5 PiB for an array with shape (64027488, 40693691) and data type int64"
     ]
    }
   ],
   "source": [
    "# 2. Preprocessare i dati\n",
    "# Codificare la colonna 'titleType' con LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "dirty_data['titleType'] = label_encoder.fit_transform(dirty_data['titleType'])\n",
    "\n",
    "# Binarizzare la colonna 'genres'\n",
    "dirty_data['genres'] = dirty_data['genres'].apply(lambda x: x.split(','))\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_binarized = mlb.fit_transform(dirty_data['genres'])\n",
    "\n",
    "# Utilizzare TF-IDF per la colonna 'primaryTitle'\n",
    "tfidf = TfidfVectorizer()\n",
    "primaryTitle_tfidf = tfidf.fit_transform(dirty_data['primaryTitle'])\n",
    "\n",
    "# Concatenare tutte le features\n",
    "import numpy as np\n",
    "X = np.hstack((dirty_data[['titleType', 'isAdult', 'runtimeMinutes']].values, primaryTitle_tfidf.toarray()))\n",
    "\n",
    "# La colonna target è 'genres'\n",
    "y = genres_binarized\n",
    "\n",
    "# 3. Dividere il dataset in train e test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Addestrare il modello\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Valutare il modello\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcolare la accuracy e f1 score per ogni etichetta di genere e poi fare una media\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
