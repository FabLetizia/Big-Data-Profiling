PUT FILES ON THE NODE:
scp -i path/to/your_key.pem -r path/to/local/file.csv hadoop@your-master-node.amazonaws.com:~
scp -i path/to/your_key.pem -r path/to/your_script.py hadoop@your-master-node.amazonaws.com:~


ACCESS THE MASTER NODE:
ssh -i path/to/your_key.pem hadoop@your-master-node.amazonaws.com


CREATE THE INPUT FOLDER ON HDFS:
hdfs dfs -mkdir /input


CREATE THE OUTPUT FOLDER ON HDFS:
hdfs dfs -mkdir /output


MOVE FILES IN THE INPUT FOLDER:
hdfs dfs -put path/to/local/file.csv /input


INSTALL LIBRARIES ON HDFS:
pip install matplotlib
pip install pyspark
pip install ydata_profiling
pip uninstall urllib3
pip install urllib3==1.26.14


RUN THE JOB:
$SPARK_HOME/bin/spark-submit --master yarn path/to/your_script.py --input_path hdfs:///input/file.csv


DOWNLOAD THE OUTPUT FILE IN LOCAL PATH:
scp -i path/to/your_key.pem hadoop@your-master-node.amazonaws.com:output.html path/to/destination/